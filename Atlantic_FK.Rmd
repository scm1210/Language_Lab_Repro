---
title: "Formality Project: Atlantic Flesch-Kincaid and Data Viz"
author: "Steven Mesquiti"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    df_print: paged
    highlight: tango
    theme: united
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
---

```{r setup, include=FALSE, message=FALSE}
# set chunk options for the document
# include=FALSE means that this chunk will not show up in the report

knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, cache = FALSE, dpi = 150, fig.path = "Atlantic_figs") 
# echo = TRUE means that the source code will be displayed
# message = FALSE suppresses messages
# warning = FALSE suppresses warnings
# cache = FALSE recompiles from scratch each time you knit 
# dpi = 150 sets the figure resolution
# fig.path specifies a directory where figures will be output

options(digits = 4) 
set.seed(65) #set seed for random number generation
```

## Set working directory 

```{r}
setwd("~/Desktop/working-with-lyle/formality_project")
if (!require("pacman")) install.packages("pacman") #run this if you don't have pacman 
library(pacman)
pacman::p_load(tidyverse,rlang, zoo, lubridate, plotrix, ggpubr, caret, broom, kableExtra, reactable, install = T) 
#use pacman to load packages quickly 
```

## Set plot aesthetics 

```{r}
palette_map = c("#3B9AB2", "#EBCC2A", "#F21A00")
palette_condition = c("#ee9b00", "#bb3e03", "#005f73")

plot_aes = theme_classic() +
  theme(legend.position = "top",
        legend.text = element_text(size = 12),
        text = element_text(size = 16, family = "Futura Medium"),
        axis.text = element_text(color = "black"),
        axis.line = element_line(colour = "black"),
        axis.ticks.y = element_blank())
```

## Set table function 

```{r}
 table_model = function(model_data,reference = "Intercept") {
   model_data %>% 
     tidy() %>% 
     rename("SE" = std.error,
            "t" = statistic,
            "p" = p.value) %>%
     mutate(term = gsub("\\(Intercept\\)", !!reference, term),
            term = gsub("Date", "Original Publication Date", term)) %>%
     kable() %>% 
     kableExtra::kable_styling()
   
 }
```

## Load in an clean data 

```{r}
df <- read_csv('Atlantic_Cleaned_all_vars.csv') #read in the data


#screen outliers
df[,c("Analytic_scaled", "WPS_scaled", "BigWords_scaled","Period_scaled","readability_scaled","grade_level_scaled",'i_scaled','we_scaled','pronoun_scaled','article_scaled','cogproc_scaled','Apostro_scaled',"Conversation_scaled", 'det_scaled','syllables_per_word_scaled','syllables_per_sentence_scaled')] <- lapply(df[,c("Analytic","WPS","BigWords","Period","readability","grade_level",'i','we','pronoun','article','cogproc','Apostro',"Conversation",'det','syllables_per_word','syllables_per_sentence')], scale)

df <- subset(df, abs(Analytic_scaled) <= 3 & abs(WPS_scaled) <= 3 & abs(BigWords_scaled) <= 3 
             & abs(Period_scaled) <= 3 & abs(readability_scaled) <= 3  & abs(grade_level_scaled) <= 3 & abs(i_scaled)
             <= 3 & abs(we_scaled) <= 3 & abs(pronoun_scaled) <= 3 & abs(article_scaled) <= 3 & abs(cogproc_scaled) <= 3 & abs(Apostro_scaled) & abs(Conversation_scaled) & abs(det_scaled))



df <- df %>% filter(readability<=120) %>% #filter out impossible values
  filter(readability>=0) %>% 
  filter(grade_level>=0) %>% 
    filter(grade_level<=18) %>% 
  filter(Period>0) %>% 
  filter(Period<=20) %>% 
  filter(WPS<145)



```

## Tidy the data

```{r, include=F}
tidy_df <- df %>%
   group_by(Date) %>% ###grouping by the year 
  mutate_at(vars("Analytic","WPS","BigWords","Period","readability","grade_level",'i','we','det','article','cogproc','Apostro',"Conversation",'syllables_per_word','syllables_per_sentence'), as.numeric) %>% 
   summarise_at(vars("Analytic","WPS","BigWords","Period","readability",'grade_level','i','we','det','article','cogproc','Apostro',"Conversation",'syllables_per_word','syllables_per_sentence'),  funs(mean, std.error),) 

# Get the mean values for the year 1857
year_means <- tidy_df %>%
  filter(Date == 1857) 

#create centered variables on 1857
tidy_df$Analytic_centered <- tidy_df$Analytic_mean - 79.11
tidy_df$WPS_centered <- tidy_df$WPS_mean - 25.1	
tidy_df$BigWords_centered <- tidy_df$BigWords_mean - 20.79
tidy_df$Period_centered <- tidy_df$Period_mean - 3.931
tidy_df$readability_centered <- tidy_df$readability_mean - 60.05
tidy_df$grade_level_centered <- tidy_df$grade_level_mean - 11.01	
tidy_df$i_centered <- tidy_df$i_mean - 1.153
tidy_df$we_centered <- tidy_df$we_mean - 0.86	
tidy_df$det_centered <- tidy_df$det_mean - 16.79
tidy_df$article_centered <- tidy_df$article_mean - 9.062
tidy_df$cogproc_centered<- tidy_df$cogproc_mean - 8.857
tidy_df$Apostro_centered <- tidy_df$Apostro_mean - 1.36
tidy_df$Conversation_centered <- tidy_df$Conversation_mean - 0.153
tidy_df$syllables_per_word_centered <- tidy_df$syllables_per_word_mean - 1.439
tidy_df$syllables_per_sentence_centered <- tidy_df$syllables_per_sentence_mean - 35.57

```


# Flesch-Kincaid Description 

**Flesch-Kincaid Ease of Readability**: higher scores indicate material that is easier to read; lower numbers mark passages that are more difficult to read.

**The Fleschâ€“Kincaid Grade Level Score**: presents a score as a U.S. grade level, making it easier for teachers, parents, librarians, and others to judge the readability level of various books and texts.


# Corpus Summary Stats {.tabset}

The following corpus consists of **42,528 articles** ranging from **1857 to 2022**.

## Dates

```{r}
df %>% 
  select(Date) %>% 
  range()
```


## Raw count of Articles

Number arrived at after filtering out outliers and duplicates

```{r}
df %>%
  select(Filename) %>%
  dplyr::summarize(n = n()) %>%
  reactable::reactable(striped = TRUE)
```

## Number of Articles per Year 

```{r}
articles_year <- df %>%
  select(Filename,Date) %>%
  unique() %>%
  group_by(Date) %>%
  dplyr::summarize(n = n()) %>%
  reactable::reactable(striped = TRUE)
 articles_year
```


# Flesch-Kincaid Graphs {.tabset}

Please see attached files for the graphs if needed.

```{r eval=FALSE, include=FALSE}
#define k-fold cross validation method
ctrl <- trainControl(method = "cv", number = 5)
grid <- expand.grid(span = seq(0.5, 0.9, len = 5), degree = 1)

#Readability 
read <- train(Date ~ readability, data = df, method = "gamLoess", tuneGrid=grid, trControl = ctrl)
read
#0.5 is the best 

#Grade Level 
grade <- train(Date ~ grade_level, data = df, method = "gamLoess", tuneGrid=grid, trControl = ctrl)
grade
#0.6 also the best 
```

## Plotting the smoothed data by year

```{r, fig.width=12,fig.height=12}
readability_smooth_tidy <- ggplot(data=tidy_df, aes(x=Date, y=readability_mean, group=1)) +
  ggtitle("Readability") +
  geom_point(color = "dodgerblue3", alpha = 0.7) + 
  geom_smooth(method = "loess", span = 0.60 )+ 
  plot_aes +
  labs(x = "Year", y = 'Ease of Readability') +
  theme(axis.text.x=element_text(angle=45, hjust=1), 
        plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16)) +
  theme(plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16)) + 
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=20,face="bold"))+
  theme(plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 20)) +
  theme(axis.text=element_text(size = 14),
        axis.title=element_text(size = 20,face="bold"))

grade_smooth_tidy <- ggplot(data=tidy_df, aes(x=Date, y=grade_level_mean, group=1)) +
  ggtitle("Grade Level") +
  geom_point(color = "dodgerblue3", alpha = 0.7) + 
  geom_smooth(method = "loess", span = 0.80 )+ 
  plot_aes +
  labs(x = "Year", y = 'Grade Level Score') +
  theme(axis.text.x=element_text(angle=45, hjust=1), 
        plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16)) +
  theme(plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16)) + 
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=20,face="bold"))+
  theme(plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 20)) +
  theme(axis.text=element_text(size = 14),
        axis.title=element_text(size = 20,face="bold"))

syllables_per_word_smooth_tidy <- ggplot(data=tidy_df, aes(x=Date, y=syllables_per_word_mean, group=1)) +
  ggtitle("Syllables per word") +
  geom_point(color = "dodgerblue3", alpha = 0.7) + 
  geom_smooth(method = "loess", span = 0.80 )+ 
  plot_aes +
  labs(x = "Year", y = 'Syllables per word') +
  theme(axis.text.x=element_text(angle=45, hjust=1), 
        plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16)) +
  theme(plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16)) + 
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=20,face="bold"))+
  theme(plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 20)) +
  theme(axis.text=element_text(size = 14),
        axis.title=element_text(size = 20,face="bold"))

syllables_per_sentence_smooth_tidy <- ggplot(data=tidy_df, aes(x=Date, y=syllables_per_sentence_mean, group=1)) +
  ggtitle("Syllables per sentence") +
  geom_point(color = "dodgerblue3", alpha = 0.7) + 
  geom_smooth(method = "loess", span = 0.80 )+ 
  plot_aes +
  labs(x = "Year", y = 'Syllables per sentence') +
  theme(axis.text.x=element_text(angle=45, hjust=1), 
        plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16)) +
  theme(plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16)) + 
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=20,face="bold"))+
  theme(plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 20)) +
  theme(axis.text=element_text(size = 14),
        axis.title=element_text(size = 20,face="bold"))

syllables_per_word_smooth_tidy <- ggplot(data=tidy_df, aes(x=Date, y=syllables_per_word_mean, group=1)) +
  ggtitle("Syllables per word") +
  geom_point(color = "dodgerblue3", alpha = 0.7) + 
  geom_smooth(method = "loess", span = 0.80 )+ 
  plot_aes +
  labs(x = "Year", y = 'Syllables per word') +
  theme(axis.text.x=element_text(angle=45, hjust=1), 
        plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16)) +
  theme(plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 16)) + 
  theme(axis.text=element_text(size=16),
        axis.title=element_text(size=20,face="bold"))+
  theme(plot.title.position = 'plot', 
        plot.title = element_text(hjust = 0.5, face = "bold", size = 20)) +
  theme(axis.text=element_text(size = 14),
        axis.title=element_text(size = 20,face="bold"))


tidy_smooth_graphs <- ggpubr::ggarrange(readability_smooth_tidy,grade_smooth_tidy,
                                        syllables_per_word_smooth_tidy,
                                        ncol=1, nrow=3, common.legend = TRUE, legend = "bottom")
annotate_figure(tidy_smooth_graphs,
                top = text_grob("Atlantic Flesch-Kincaid and Syllables",  color = "black", face = "bold", size = 20))

```

## Individual Graphs 

```{r}
readability_smooth_tidy 
grade_smooth_tidy
syllables_per_sentence_smooth_tidy
syllables_per_word_smooth_tidy
```

# Build Simple Regression Models {.tabset}

## Ease of Readability 

Model presented is centered on means for first year in the dataset.


```{r}
#Centered 
Readability_centered <- lm(readability_centered ~ Date, data = tidy_df)

table_model(Readability_centered)
```

## Grade Level Reading

Model presented is centered on means for first year in the dataset.


```{r}
#Centered 

Grade_centered <- lm(grade_level_centered ~ Date, data = tidy_df)

table_model(Grade_centered)
```

## Syllables per Words

```{r}
syllables_per_word_centered <- lm(syllables_per_word_centered ~ Date, data = tidy_df)
table_model(syllables_per_word_centered)
```
